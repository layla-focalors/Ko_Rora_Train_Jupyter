{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lora Trainer Remaked by layla-focalors  \n",
    "This is based on thr work of Hollowstrawberry. Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import toml\n",
    "import shutil\n",
    "import zipfile\n",
    "from time import time\n",
    "\n",
    "# 프로젝트 이름은 이미지가 포함된 폴더와 동일합니다. 공백은 허용되지 않습니다.\n",
    "\n",
    "# 수정 가능\n",
    "PROJECT_NAME = 'Project'\n",
    "\n",
    "# 수정을 권장하지 않음\n",
    "FOLDER_STRUCTURE = f'/Loras/{PROJECT_NAME}/dataset'\n",
    "TRAINING_MODEL = 'https://huggingface.co/Lykon/AnyLoRA/resolve/main/AnyLoRA_noVae_fp16-pruned.ckpt'\n",
    "\n",
    "# 512의 해상도는 Stable Diffusion 1.5의 표준입니다. 고해상도 학습은 훨씬 느리지만 더 나은 세부 정보로 이어질 수 있습니다.\n",
    "\n",
    "# 최상의 결과를 얻기 위해 학습하는 동안 이미지의 크기가 자동으로 조정되므로 직접 자르거나 크기를 조정할 필요가 없습니다.\n",
    "\n",
    "RESOLUTION = 512\n",
    "\n",
    "# 이 옵션은 추가 비용 없이 이미지를 정상적으로 훈련하고 뒤집어 더 많은 것을 학습합니다. 이미지가 20개 미만인 경우 특별히 켜십시오.\n",
    "\n",
    "# Lora의 비대칭 요소에 관심이 있다면 끄십시오.\n",
    "\n",
    "FLIP_AUG = False\n",
    "\n",
    "# 이미지는 훈련 중에 이 횟수만큼 반복됩니다. 이미지에 반복을 곱한 값은 200에서 400 사이가 좋습니다.\n",
    "\n",
    "NUM_REPEATS = 10\n",
    "\n",
    "# 훈련할 기간을 선택합니다. 좋은 시작점은 약 10 epoch 또는 약 2000 단계입니다.\n",
    "\n",
    "# 하나의 Epoch는 이미지 수에 반복을 곱한 후 배치 크기로 나눈 값과 같은 단계입니다.\n",
    "\n",
    "PREFERRED_UNIT = 'Epoches'\n",
    "PREFFERED_DURATION = 10\n",
    "\n",
    "# 배치 크기를 늘리면 학습 속도가 빨라지지만 학습 속도가 느려질 수 있습니다. 권장 2 또는 3.\n",
    "\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "\n",
    "# 학습률은 결과에 가장 중요합니다. 영상이 많을 때 더 느리게 훈련시키고 싶거나 dim과 alpha가 높은 경우에는 unet을 2e-4 이하로 옮기십시오.\n",
    "\n",
    "# 텍스트 인코더는 Lora가 개념을 약간 더 잘 배울 수 있도록 도와줍니다. unet의 절반 또는 5 분의 1로 만드는 것이 좋습니다. 스타일을 훈련하는 경우 0으로 설정할 수도 있습니다.\n",
    "\n",
    "UNET_LR = '5e-4'\n",
    "TEXT_ENCODER_LR = '1e-4'\n",
    "\n",
    "# Code\n",
    "# Create Config\n",
    "\n",
    "XFORMERS = True\n",
    "COMMIT = \"9a67e0df390033a89f17e70df5131393692c2a55\"\n",
    "BETTER_EPOCH_NAMES = True\n",
    "LOAD_TRUNCATED_IMAGES = True\n",
    "project_name = PROJECT_NAME\n",
    "custom_model_is_based_on_sd2 = False\n",
    "resolution = RESOLUTION\n",
    "flip_aug = FLIP_AUG\n",
    "num_repeats = NUM_REPEATS\n",
    "preferred_unit = PREFERRED_UNIT\n",
    "preferred_duration = PREFFERED_DURATION\n",
    "train_batch_size = TRAIN_BATCH_SIZE\n",
    "unet_lr = UNET_LR\n",
    "text_encoder_lr = TEXT_ENCODER_LR\n",
    "\n",
    "caption_extension = \".txt\"\n",
    "shuffle_tags = True \n",
    "shuffle_caption = shuffle_tags\n",
    "activation_tags = \"1\" \n",
    "keep_tokens = int(activation_tags)\n",
    "\n",
    "how_many = preferred_unit\n",
    "\n",
    "max_train_epochs = how_many if preferred_unit == \"Epochs\" else None\n",
    "max_train_steps = how_many if preferred_unit == \"Steps\" else None\n",
    "save_every_n_epochs = 1\n",
    "\n",
    "keep_only_last_n_epochs = 10\n",
    "if not save_every_n_epochs:\n",
    "  save_every_n_epochs = max_train_epochs\n",
    "if not keep_only_last_n_epochs:\n",
    "  keep_only_last_n_epochs = max_train_epochs\n",
    "\n",
    "lr_scheduler = \"cosine_with_restarts\"\n",
    "lr_scheduler_number = 3\n",
    "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
    "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
    "\n",
    "lr_warmup_ratio = 0\n",
    "lr_warmup_steps = 0\n",
    "\n",
    "lora_type = \"LoRA\"\n",
    "network_dim = 16 \n",
    "network_alpha = 8\n",
    "\n",
    "conv_dim = 8\n",
    "conv_alpha = 4\n",
    "\n",
    "optimizer = \"AdamW8bit\"\n",
    "override_values_for_dadapt_and_prodigy = True\n",
    "\n",
    "network_module = \"networks.lora\"\n",
    "network_args = None\n",
    "if lora_type.lower() == \"locon\":\n",
    "  network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"]\n",
    "\n",
    "if optimizer.lower() == \"prodigy\" or \"dadapt\" in optimizer.lower():\n",
    "  if override_values_for_dadapt_and_prodigy:\n",
    "    unet_lr = 0.5\n",
    "    text_encoder_lr = 0.5\n",
    "    lr_scheduler = \"constant_with_warmup\"\n",
    "    lr_warmup_ratio = 0.05\n",
    "    network_alpha = network_dim\n",
    "  if not optimizer_args:\n",
    "    optimizer_args = [\"decouple=True\",\"weight_decay=0.01\",\"betas=[0.9,0.999]\"]\n",
    "    if optimizer == \"Prodigy\":\n",
    "      optimizer_args.extend([\"d_coef=2\",\"use_bias_correction=True\"])\n",
    "      if lr_warmup_ratio > 0:\n",
    "        optimizer_args.append(\"safeguard_warmup=True\")\n",
    "      else:\n",
    "        optimizer_args.append(\"safeguard_warmup=False\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
